{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Assumption: rows in the dataset are i.i.d.\n",
    "- Feature: признак(фича).\n",
    "- Design matrix: Everything (all features) except the target.\n",
    "    - Матрица признаков.\n",
    "\n",
    "- **Model**: задает какое-то отображение из features в target.\n",
    "    - из про-ва признаков в про-во оценок.\n",
    "- **Loss function**: позволяет оценить качество нашей модели.\n",
    "- **Hyperparameter**: они относятся к модели. We use the model's hyperparameters to influence the way it will train the data.\n",
    "    - Гиперпараметер.\n",
    "    \n",
    "# 1. Maximum likelihood estimation\n",
    "\n",
    "- Метод максимального правдоподобия.\n",
    "- Maximum likelihood estimation is a method that determines values for the parameters of a model. The parameter values are found such that they maximise the likelihood that the process described by the model produced the data that were actually observed.\n",
    "\n",
    "\n",
    "Likelihood function:\n",
    "\n",
    "![alt text](https://i.ibb.co/mT5DB8S/Screen-Shot-2020-09-04-at-16-37-31.png)\n",
    "\n",
    "- Это условное распределение выборки при условии, что параметров $\\theta$.\n",
    "- I.e. насколько вероятно было получить выборку $\\{X, Y\\}$ при условии, что параметр имеет значения $\\theta$.\n",
    "    - *получить выборку*: имеется в виду получить объект $X_i$ (a row from the design matrix) c target $y_i$.\n",
    "- На $\\theta$ какое-то распределение может быть, но функция прадоподобия $\\theta \\neq$ распредение $\\theta$.\n",
    "\n",
    "![alt text](https://i.ibb.co/9NG5cV2/Screen-Shot-2020-09-04-at-16-47-27.png)\n",
    "\n",
    "То есть\n",
    "\n",
    "- **Задача**: найти более правдоподобный параметр. Тот, который лучше всего описывает нашу выборку.\n",
    "\n",
    "\n",
    "![alt text](https://i.ibb.co/7z1TgRm/Screen-Shot-2020-09-04-at-16-50-32.png)\n",
    "\n",
    "![alt text](https://i.ibb.co/7nSTMQP/Screen-Shot-2020-09-04-at-16-51-20.png)\n",
    "\n",
    "---\n",
    "\n",
    "# 2. Supervised Learning Problem Statement.\n",
    "\n",
    "- When there is a target.\n",
    "\n",
    "![alt text](https://i.ibb.co/Qj41CYC/Screen-Shot-2020-09-04-at-17-21-46.png)\n",
    "\n",
    "- While we don't know what Loss function we are going to use, we shouldn't collect any data.\n",
    "\n",
    "---\n",
    "\n",
    "# 3. Unsupervised Learning Problem Statement.\n",
    "\n",
    "- When there is no target.\n",
    "\n",
    "---\n",
    "\n",
    "# 4. Naive Bayes Classifier.\n",
    "\n",
    "![alt text](https://i.ibb.co/gMqchc4/Screen-Shot-2020-09-04-at-17-32-46.png)\n",
    "\n",
    "---\n",
    "\n",
    "## 4.1. Bayes' Theorem.\n",
    "\n",
    "![alt text](https://i.ibb.co/mys93LZ/Screen-Shot-2020-09-04-at-17-33-51.png) \n",
    "\n",
    "Тут подход такой:\n",
    "\n",
    "- Давайте прикинем условную вероятность метки класса при условии того, что объект описивается какими-то фичами. То есть:\n",
    "\n",
    "![alt text](https://i.ibb.co/6bxtxqm/Screen-Shot-2020-09-04-at-17-51-14.png)\n",
    "\n",
    "- Оцениваем $P(y_i = C_k)$ как частота каждого класса в нашей выборке.\n",
    "- **Naive assumption**: features are independent. In order to factorize the probabilities.\n",
    "- $\\mathbf{x_i} = (x_i^1, x_i^2, \\ldots, x_i^p)$- a vector, corresponding to the $i$-th row in the design matrix.\n",
    "- $x_i^l$ - is the $l$-th components of $\\mathbf{x_i}$, corresponding to the value of the $l$-th feature for the i-th rows in the design matrix.\n",
    "\n",
    "![alt text](https://i.ibb.co/4P09SBJ/Screen-Shot-2020-09-04-at-17-59-17.png)\n",
    "\n",
    "Тогда\n",
    "\n",
    "![alt text](https://i.ibb.co/fNKX8XY/Screen-Shot-2020-09-04-at-18-00-57.png)\n",
    "\n",
    "To find maximum we don't need the denominator, but without it it's no longer a probability.\n",
    "\n",
    "---\n",
    "\n",
    "# 5. kNN.\n",
    "\n",
    "Есть зеленная точка. Она красный треугольник или синий квадрат?\n",
    "\n",
    "![alt text](https://i.ibb.co/G9X3t9w/Screen-Shot-2020-09-04-at-18-25-28.png)\n",
    "\n",
    "- Чем ближе к объектам, тем больше они похожие.\n",
    "\n",
    "![alt text](https://i.ibb.co/7X3W0hK/Screen-Shot-2020-09-04-at-18-30-19.png)\n",
    "\n",
    "- Here we have a hyperparameter: how to choose the right number of neighbors $k$. Перебором можно это сделать.\n",
    "\n",
    "---\n",
    "\n",
    "## 5.1. Weighted kNN.\n",
    "\n",
    "- Instead of choosing the class of the most frequent neighbor we:\n",
    "    - Calculate the distance to $k$ neighbors.\n",
    "    - For each neighbor we define a weight $w(\\mathbf{x}_{(i)}) = w_i$, such that $w_i \\sim \\frac{1}{|| \\mathbf{x} - \\mathbf{x}_{(i)}||}$.\n",
    "    - Normalize the weight for each class (not for each neighbor): $$w_{\\text{blue}} = \\frac{w(\\mathbf{x}_{(1)}) + w(\\mathbf{x}_{(2)}) + w(\\mathbf{x}_{(3)})}{\\text{sum of all weights}}$$.\n",
    "    - We choose the class with the largest weight.\n",
    "    ![alt text](https://i.ibb.co/x61ZjDs/Screen-Shot-2020-09-04-at-18-36-38.png)\n",
    "    \n",
    "---\n",
    "\n",
    "## 5.2. What about Regression?\n",
    "\n",
    "- Above we talked only about classification.\n",
    "- В этом случае каждому объекту соответствует какое-то число вместо какого-то цвета. Можно смотреть все точки вокруг и усредним.\n",
    "\n",
    "## 5.3. Notes.\n",
    "\n",
    "- We have to normalize the design matrix before fiting kNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
