{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3HSFVUY02ey2"
   },
   "source": [
    "## seq2seq practice\n",
    "### Generating names with recurrent neural networks\n",
    "\n",
    "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
    "\n",
    "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
    "\n",
    "It's dangerous to go alone, take these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true,
    "id": "32Dua7RK2ey3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrA0GfI62ey3"
   },
   "source": [
    "# Our data\n",
    "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
    "\n",
    "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "id": "s6qFLyqn2ey3"
   },
   "outputs": [],
   "source": [
    "start_token = \" \"\n",
    "\n",
    "def read_names(path_to_file):\n",
    "    global start_token\n",
    "    \n",
    "    with open(path_to_file) as f:\n",
    "        names = f.read()[:-1].split('\\n')\n",
    "        names = [start_token + line for line in names]\n",
    "        return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true,
    "id": "1nKFC70t2ey3"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    names = read_names('names.txt')\n",
    "except FileNotFoundError:\n",
    "    !wget https://raw.githubusercontent.com/girafe-ai/ml-mipt/master/datasets/names_dataset/names -nc -O names\n",
    "    names = read_names('./names')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "id": "DmdW7qih2ey3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n samples =  7944\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print ('n samples = ',len(names))\n",
    "for x in names[::1000]:\n",
    "    print (x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "9\n",
      "6\n",
      "8\n",
      "8\n",
      "6\n",
      "9\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "for x in list(map(len, names))[::1000]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "gZbTXopI2ey3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length = 16\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\nHFA/zMosAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len, names))\n",
    "print(\"max length =\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, names)),bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aB3n1Jsv2ey3"
   },
   "source": [
    "# Text processing\n",
    "\n",
    "First we need next to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ', 'A', 'a', 'b', 'e', 'g', 'l'}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(names[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ', 'A', 'a', 'b', 'g', 'i', 'l'}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ', 'A', 'a', 'b', 'g', 'i', 'l'}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set() | set(names[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokens = set()\n",
    "\n",
    "for name in names:\n",
    "    tokens = (tokens | set(name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "-Jq4Y00h2ey3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_tokens =  55\n"
     ]
    }
   ],
   "source": [
    "tokens = set()\n",
    "\n",
    "for name in names:\n",
    "    tokens.update(set(name))\n",
    "\n",
    "tokens = list(tokens)\n",
    "\n",
    "num_tokens = len(tokens)\n",
    "print ('num_tokens = ', num_tokens)\n",
    "\n",
    "assert 50 < num_tokens < 60, \"Names should contain within 50 and 60 unique tokens depending on encoding\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tLcIgmb2ey3"
   },
   "source": [
    "### Convert characters to integers\n",
    "\n",
    "Torch is built for crunching numbers, not strings. \n",
    "To train our neural network, we'll need to replace characters with their indices in tokens list.\n",
    "\n",
    "Let's compose a dictionary that does this mapping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_values = list(map(ord, tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true,
    "id": "m8KGPr8m2ey4"
   },
   "outputs": [],
   "source": [
    "token_to_id = {token:idx for idx, token in enumerate(tokens)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' ': 36,\n",
       " \"'\": 37,\n",
       " '-': 23,\n",
       " 'A': 5,\n",
       " 'B': 11,\n",
       " 'C': 51,\n",
       " 'D': 16,\n",
       " 'E': 45,\n",
       " 'F': 13,\n",
       " 'G': 29,\n",
       " 'H': 38,\n",
       " 'I': 41,\n",
       " 'J': 44,\n",
       " 'K': 54,\n",
       " 'L': 4,\n",
       " 'M': 19,\n",
       " 'N': 26,\n",
       " 'O': 53,\n",
       " 'P': 14,\n",
       " 'Q': 22,\n",
       " 'R': 7,\n",
       " 'S': 15,\n",
       " 'T': 33,\n",
       " 'U': 50,\n",
       " 'V': 21,\n",
       " 'W': 0,\n",
       " 'X': 8,\n",
       " 'Y': 10,\n",
       " 'Z': 48,\n",
       " 'a': 24,\n",
       " 'b': 40,\n",
       " 'c': 6,\n",
       " 'd': 52,\n",
       " 'e': 1,\n",
       " 'f': 32,\n",
       " 'g': 34,\n",
       " 'h': 39,\n",
       " 'i': 28,\n",
       " 'j': 43,\n",
       " 'k': 25,\n",
       " 'l': 46,\n",
       " 'm': 9,\n",
       " 'n': 17,\n",
       " 'o': 12,\n",
       " 'p': 3,\n",
       " 'q': 31,\n",
       " 'r': 47,\n",
       " 's': 2,\n",
       " 't': 30,\n",
       " 'u': 27,\n",
       " 'v': 18,\n",
       " 'w': 20,\n",
       " 'x': 35,\n",
       " 'y': 49,\n",
       " 'z': 42}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_to_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "DYvvG0fu2ey4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seems alright!\n"
     ]
    }
   ],
   "source": [
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\"\n",
    "\n",
    "for i in range(num_tokens):\n",
    "    assert token_to_id[tokens[i]] == i, \"token identifier must be it's position in tokens list\"\n",
    "\n",
    "print(\"Seems alright!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting to matrix:\n",
    "- For a given name, convert each character in name to its id. This gives a list of number.\n",
    "- Generate a matrix of dimensions $m\\times n$ where $m = \\text{len(names)}$ and $n = \\text{max(len(names))}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true,
    "id": "2-OyTCDZ2ey4"
   },
   "outputs": [],
   "source": [
    "def to_matrix(names, max_len=None, pad=token_to_id[' '], dtype='int32', batch_first = True):\n",
    "    \"\"\"Casts a list of names into rnn-digestable matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, names))\n",
    "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        line_ix = [token_to_id[c] for c in names[i]]\n",
    "        names_ix[i, :len(line_ix)] = line_ix\n",
    "        \n",
    "    if not batch_first: # convert [batch, time] into [time, batch]\n",
    "        names_ix = np.transpose(names_ix)\n",
    "\n",
    "    return names_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "id": "qDULmi9I2ey4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Abagael', ' Abagail']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_to_id[' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = 5 or 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "6 or 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "bG5y27M62ey4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Abagael\n",
      " Glory\n",
      " Prissie\n",
      " Giovanne\n",
      "[[36  5 40 24 34 24  1 46 36]\n",
      " [36 29 46 12 47 49 36 36 36]\n",
      " [36 14 47 28  2  2 28  1 36]\n",
      " [36 29 28 12 18 24 17 17  1]]\n"
     ]
    }
   ],
   "source": [
    "#Example: cast 4 random names to matrices, pad with zeros\n",
    "print('\\n'.join(names[::2000]))\n",
    "print(to_matrix(names[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cQrt18182ey4"
   },
   "source": [
    "# Recurrent neural network\n",
    "\n",
    "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
    "<img src=\"https://github.com/girafe-ai/ml-mipt/blob/basic_f20/week0_10_RNN_and_Language_models/rnn.png?raw=1\" width=480>\n",
    "\n",
    "Since we're training a language model, there should also be:\n",
    "* An embedding layer that converts character id $x_t$ to a vector.\n",
    "* An output layer that predicts probabilities of next phoneme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true,
    "id": "_ywO38A_2ey4"
   },
   "outputs": [],
   "source": [
    "import torch, torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "emb_test = nn.Embedding(55, 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_batch = torch.from_numpy(to_matrix(names[::2000])).type(torch.LongTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Abagael', ' Glory', ' Prissie', ' Giovanne']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[::2000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[36,  5, 40, 24, 34, 24,  1, 46, 36],\n",
       "        [36, 29, 46, 12, 47, 49, 36, 36, 36],\n",
       "        [36, 14, 47, 28,  2,  2, 28,  1, 36],\n",
       "        [36, 29, 28, 12, 18, 24, 17, 17,  1]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 9])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 9, 16])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_test(example_batch).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7068,  1.3573,  0.2379,  0.3142, -0.6745,  1.4368,  0.0734,  0.0252,\n",
       "          0.3874, -0.3137, -0.5973,  0.6109,  0.2696,  1.0783,  0.6352,  0.4393],\n",
       "        [ 0.0877,  1.9207, -1.8638, -0.6919, -0.5646, -0.8248, -0.1265,  0.8627,\n",
       "          0.0721, -0.3290, -0.0810,  0.2013, -0.6295,  0.1990, -0.7842, -1.6983],\n",
       "        [ 0.3265,  0.4531, -1.5284,  0.2923,  0.3217, -1.4250,  0.9495,  0.3830,\n",
       "         -1.0423, -0.5986,  2.4670,  1.4030,  0.0603, -2.1798, -0.0672,  0.5265],\n",
       "        [-0.0848, -1.0753, -1.4100, -0.9616, -0.7059, -0.0265, -0.2403,  0.9818,\n",
       "          0.4726,  1.1465, -0.7368, -1.8379, -0.8011, -1.6636, -0.5127,  0.3304],\n",
       "        [ 1.5209,  0.4673,  0.9926,  0.7492, -0.7121, -0.4425, -1.1537, -0.7161,\n",
       "         -1.0161,  1.3275,  0.2780, -0.2651,  0.0966, -0.3926, -0.9665,  0.7608],\n",
       "        [-0.0848, -1.0753, -1.4100, -0.9616, -0.7059, -0.0265, -0.2403,  0.9818,\n",
       "          0.4726,  1.1465, -0.7368, -1.8379, -0.8011, -1.6636, -0.5127,  0.3304],\n",
       "        [-0.6657, -0.8770,  0.2952, -0.1075,  1.5325,  0.4315, -0.0084, -1.4248,\n",
       "         -1.5514, -1.5358,  0.5986, -2.3366, -0.2181, -1.3917,  0.4279,  0.6555],\n",
       "        [ 0.2609,  0.3566,  0.2002,  0.7255,  0.3428, -1.7760,  0.0289, -0.4786,\n",
       "         -0.8673, -1.1133, -0.6735, -0.5338,  0.4880, -1.2287, -0.8417,  0.6055],\n",
       "        [-1.7068,  1.3573,  0.2379,  0.3142, -0.6745,  1.4368,  0.0734,  0.0252,\n",
       "          0.3874, -0.3137, -0.5973,  0.6109,  0.2696,  1.0783,  0.6352,  0.4393]],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_test(example_batch)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true,
    "id": "oLPmFaje2ey4"
   },
   "outputs": [],
   "source": [
    "class CharRNNCell(nn.Module):\n",
    "    \"\"\"\n",
    "    Implement the scheme above as torch module\n",
    "    \"\"\"\n",
    "    def __init__(self, num_tokens=len(tokens), embedding_size=16, rnn_num_units=64):\n",
    "        super(self.__class__,self).__init__()\n",
    "        self.num_units = rnn_num_units\n",
    "        \n",
    "        #n_to_pick, #one will be embedded as a vector of size embedding_size\n",
    "        # we have to do this for each token, so the code below generates a embedding\n",
    "        # matrix of size num_tokens x the embedding_size that we chose.\n",
    "        self.embedding = nn.Embedding(num_tokens, embedding_size)\n",
    "        \n",
    "        # Because of concatenation n_in = rnn_num_units + embedding_size\n",
    "        self.rnn_update = nn.Linear(embedding_size + rnn_num_units, rnn_num_units)\n",
    "        self.rnn_to_logits = nn.Linear(rnn_num_units, num_tokens) #n_in, n_out\n",
    "        \n",
    "    def forward(self, x, h_prev):\n",
    "        \"\"\"\n",
    "        This method computes h_next(x, h_prev) and log P(x_next | h_next)\n",
    "        We'll call it repeatedly to produce the whole sequence.\n",
    "        \n",
    "        :param x: batch of character ids, containing vector of int64\n",
    "        :param h_prev: previous rnn hidden states, containing matrix [batch, rnn_num_units] of float32\n",
    "        \"\"\"\n",
    "        # get vector embedding of x\n",
    "        # x is of size (batches,)\n",
    "        # along axis=0 is the integer representing the given character of the given instance\n",
    "        # x_emb is of size (batches, embedding_size)\n",
    "        x_emb = self.embedding(x)\n",
    "        \n",
    "        # compute next hidden state using self.rnn_update\n",
    "        # hint: use torch.cat(..., dim=...) for concatenation\n",
    "        x_and_h = torch.cat([x_emb, h_prev], dim=-1)# YOUR CODE HERE\n",
    "        h_next = self.rnn_update(x_and_h)# YOUR CODE HERE\n",
    "        \n",
    "        h_next = torch.tanh(h_next)# YOUR CODE HERE\n",
    "        \n",
    "        assert h_next.size() == h_prev.size()\n",
    "        \n",
    "        #compute logits for next character probs\n",
    "        logits = self.rnn_to_logits(h_next)# YOUR CODE\n",
    "        \n",
    "        return h_next, logits\n",
    "    \n",
    "    def initial_state(self, batch_size):\n",
    "        \"\"\" return rnn state before it processes first input (aka h0) \"\"\"\n",
    "        return torch.zeros(batch_size, self.num_units, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true,
    "id": "PXIUUFlO2ey4"
   },
   "outputs": [],
   "source": [
    "char_rnn = CharRNNCell()\n",
    "criterion = nn.NLLLoss()# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "beRHMx4x2ey4"
   },
   "source": [
    "### RNN loop\n",
    "\n",
    "Once we've defined a single RNN step, we can apply it in a loop to get predictions on each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true,
    "id": "-49_dVDp2ey4"
   },
   "outputs": [],
   "source": [
    "def rnn_loop(char_rnn, batch_ix):\n",
    "    \"\"\"\n",
    "    Computes log P(next_character) for all time-steps in names_ix\n",
    "    :param names_ix: an int32 matrix of shape [batch, time], output of to_matrix(names)\n",
    "    \"\"\"\n",
    "    batch_size, max_length = batch_ix.size()\n",
    "    hid_state = char_rnn.initial_state(batch_size)\n",
    "    logprobs = []\n",
    "\n",
    "    # we have to process each word, character by character\n",
    "    # but we can (and have to) process all the words at at time, character by character.\n",
    "    # by taking the first character on each and feeding it to the network.\n",
    "    # That's what we do below.\n",
    "    for x_t in batch_ix.transpose(0,1):\n",
    "        # When we call model(...), we are actually calling model.__call__(...). \n",
    "        # The __call__ method on nn.Module eventually calls forward along with \n",
    "        # taking care of tracing and hooks.\n",
    "        # So char_rnn(x_t, hid_state) is the same as char_rnn.forward(x_t, hid_state)\n",
    "        hid_state, logits = char_rnn(x_t, hid_state)  # <-- here we call your one-step code\n",
    "        logprobs.append(F.log_softmax(logits, -1))\n",
    "        \n",
    "    return torch.stack(logprobs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_ix = to_matrix(names[:5])\n",
    "batch_ix = torch.tensor(batch_ix, dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_ix[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[36,  5, 40, 24, 34, 24,  1, 46],\n",
       "        [36,  5, 40, 24, 34, 24, 28, 46],\n",
       "        [36,  5, 40, 40,  1, 36, 36, 36],\n",
       "        [36,  5, 40, 40,  1, 49, 36, 36],\n",
       "        [36,  5, 40, 40, 28, 36, 36, 36]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Abagael', ' Abagail', ' Abbe', ' Abbey', ' Abbi']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([36, 36, 36, 36, 36])\n",
      "tensor([5, 5, 5, 5, 5])\n",
      "tensor([40, 40, 40, 40, 40])\n",
      "tensor([24, 24, 40, 40, 40])\n",
      "tensor([34, 34,  1,  1, 28])\n",
      "tensor([24, 24, 36, 49, 36])\n",
      "tensor([ 1, 28, 36, 36, 36])\n",
      "tensor([46, 46, 36, 36, 36])\n"
     ]
    }
   ],
   "source": [
    "emb_tr = None\n",
    "for x in batch_ix.transpose(0, 1):\n",
    "    print(x)\n",
    "    emb_tr = emb_test(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 16])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_tr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2609,  0.3566,  0.2002,  0.7255,  0.3428, -1.7760,  0.0289, -0.4786,\n",
       "        -0.8673, -1.1133, -0.6735, -0.5338,  0.4880, -1.2287, -0.8417,  0.6055],\n",
       "       grad_fn=<SelectBackward>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_tr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2609,  0.3566,  0.2002,  0.7255,  0.3428, -1.7760,  0.0289, -0.4786,\n",
       "         -0.8673, -1.1133, -0.6735, -0.5338,  0.4880, -1.2287, -0.8417,  0.6055],\n",
       "        [ 0.2609,  0.3566,  0.2002,  0.7255,  0.3428, -1.7760,  0.0289, -0.4786,\n",
       "         -0.8673, -1.1133, -0.6735, -0.5338,  0.4880, -1.2287, -0.8417,  0.6055],\n",
       "        [-1.7068,  1.3573,  0.2379,  0.3142, -0.6745,  1.4368,  0.0734,  0.0252,\n",
       "          0.3874, -0.3137, -0.5973,  0.6109,  0.2696,  1.0783,  0.6352,  0.4393],\n",
       "        [-1.7068,  1.3573,  0.2379,  0.3142, -0.6745,  1.4368,  0.0734,  0.0252,\n",
       "          0.3874, -0.3137, -0.5973,  0.6109,  0.2696,  1.0783,  0.6352,  0.4393],\n",
       "        [-1.7068,  1.3573,  0.2379,  0.3142, -0.6745,  1.4368,  0.0734,  0.0252,\n",
       "          0.3874, -0.3137, -0.5973,  0.6109,  0.2696,  1.0783,  0.6352,  0.4393]],\n",
       "       grad_fn=<EmbeddingBackward>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb_tr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 8])"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_ix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true,
    "id": "lYqA9bxb2ey4"
   },
   "outputs": [],
   "source": [
    "batch_ix = to_matrix(names[:5])\n",
    "batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
    "\n",
    "logp_seq = rnn_loop(char_rnn, batch_ix)\n",
    "\n",
    "assert torch.max(logp_seq).data.numpy() <= 0\n",
    "assert tuple(logp_seq.size()) ==  batch_ix.shape + (num_tokens,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 8, 55])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logp_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 55])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logp_seq[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([7, 55])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logp_seq[:, :-1][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zmjZdNN_2ey4"
   },
   "source": [
    "### Likelihood and gradients\n",
    "\n",
    "We can now train our neural network to minimize crossentropy (maximize log-likelihood) with the actual next tokens.\n",
    "\n",
    "To do so in a vectorized manner, we take `batch_ix[:, 1:]` - a matrix of token ids shifted i step to the left so i-th element is acutally the \"next token\" for i-th prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[36,  5, 40, 24, 34, 24,  1, 46],\n",
       "        [36,  5, 40, 24, 34, 24, 28, 46],\n",
       "        [36,  5, 40, 40,  1, 36, 36, 36],\n",
       "        [36,  5, 40, 40,  1, 49, 36, 36],\n",
       "        [36,  5, 40, 40, 28, 36, 36, 36]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5, 40, 24, 34, 24,  1, 46],\n",
       "        [ 5, 40, 24, 34, 24, 28, 46],\n",
       "        [ 5, 40, 40,  1, 36, 36, 36],\n",
       "        [ 5, 40, 40,  1, 49, 36, 36],\n",
       "        [ 5, 40, 40, 28, 36, 36, 36]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_ix[:, 1:] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=blue>Note</font>**\n",
    "\n",
    "Cross Entropy:\n",
    "\n",
    "$$L_{\\log}(Y, P) = -\\log \\operatorname{Pr}(Y|P) = - \\frac{1}{N} \\sum_{i=0}^{N-1} \\sum_{k=0}^{K-1} y_{i,k} \\log p_{i,k}$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $p_{i,k}$  is the probability of the $i$-th sample being of the $k$-th class. In our context $p_{i,k}$ is the probability that the next element is the $k$-th character.\n",
    "- $y_{i,k} = 1$ if the real label (character) is $k$ and $0$ otherwise.\n",
    "\n",
    "Below:\n",
    "- We skip the first element (character) from the (`batch_ix[:, 1:]`) since there is no $p_{i,k}$ to pair it against. There is no probability coming before the first element telling us that the first element will be `batch_ix[:, 0]`.\n",
    "- We skip the last probability (`logp_seq[:, :-1]`), since there is no $y_{i,k}$ to pair it against."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true,
    "id": "_m6Ef5IP2ey4"
   },
   "outputs": [],
   "source": [
    "predictions_logp = logp_seq[:, :-1] # we skip the predictions for the last character\n",
    "actual_next_tokens = batch_ix[:, 1:] # we skip the first character. Pytorch can work with a \n",
    "# non one-hot representation of the ground truth.\n",
    "\n",
    "# .contiguous() method checks that tensor is stored in the memory correctly to \n",
    "# get its view of desired shape.\n",
    "\n",
    "loss = criterion(predictions_logp.contiguous().view(-1, num_tokens), \n",
    "                  actual_next_tokens.contiguous().view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 7, 55])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_logp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35, 55])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_logp.contiguous().view(-1, num_tokens).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 7])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_next_tokens.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([35])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actual_next_tokens.contiguous().view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true,
    "id": "laRTNjAx2ey4"
   },
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true,
    "id": "VRCWGaTY2ey4"
   },
   "outputs": [],
   "source": [
    "for w in char_rnn.parameters():\n",
    "    assert w.grad is not None and torch.max(torch.abs(w.grad)).data.numpy() != 0, \\\n",
    "        \"Loss is not differentiable w.r.t. a weight with shape %s. Check forward method.\" % (w.size(),)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AFjJ2oFk2ey4"
   },
   "source": [
    "## The training loop\n",
    "\n",
    "We train our char-rnn exactly the same way we train any deep learning model: by minibatch sgd.\n",
    "\n",
    "The only difference is that this time we sample strings, not images or sound."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "id": "BVDyO2Q42ey4"
   },
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "char_rnn = CharRNNCell()\n",
    "criterion = nn.NLLLoss()\n",
    "opt = torch.optim.Adam(char_rnn.parameters())\n",
    "history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' Monique',\n",
       " ' Dede',\n",
       " ' Shani',\n",
       " ' Delila',\n",
       " ' Aime',\n",
       " ' Ardis',\n",
       " ' Salvador',\n",
       " ' Sidonia',\n",
       " ' Kamilah',\n",
       " ' Guy',\n",
       " ' Quinn',\n",
       " ' Devondra',\n",
       " ' Orly',\n",
       " ' Brynn',\n",
       " ' Salvidor',\n",
       " ' Charlotta',\n",
       " ' Catrina',\n",
       " ' Rafa',\n",
       " ' Kraig',\n",
       " ' Mitra',\n",
       " ' Howard',\n",
       " ' Annalee',\n",
       " ' Rene',\n",
       " ' Hailey',\n",
       " ' Manny',\n",
       " ' Dulcinea',\n",
       " ' Florinda',\n",
       " ' Hillel',\n",
       " ' Estrellita',\n",
       " ' Chrysa',\n",
       " ' Wini',\n",
       " ' Krysta']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(names, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[36,  5, 40, 24, 34, 24,  1, 46, 36],\n",
       "        [36, 29, 46, 12, 47, 49, 36, 36, 36],\n",
       "        [36, 14, 47, 28,  2,  2, 28,  1, 36],\n",
       "        [36, 29, 28, 12, 18, 24, 17, 17,  1]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([36, 29, 28, 12, 18, 24, 17, 17,  1]),\n",
       " tensor([36, 29, 46, 12, 47, 49, 36, 36, 36])]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample(list(example_batch), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "id": "SSk2IVJf2ey4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\npZSKEhrQlVIqSmhAV0qpKPH/L6T23ggPN8sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = 16\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    \n",
    "    # The batch is formed at random\n",
    "    batch_ix = to_matrix(sample(names, 32), max_len=MAX_LENGTH)\n",
    "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
    "    \n",
    "    logp_seq = rnn_loop(char_rnn, batch_ix)\n",
    "    \n",
    "    # compute loss\n",
    "    predictions_logp = logp_seq[:, :-1]# YOUR CODE HERE\n",
    "    actual_next_tokens = batch_ix[:, 1:] # YOUR CODE HERE\n",
    "\n",
    "    loss = criterion(predictions_logp.contiguous().view(-1, num_tokens), \n",
    "                  actual_next_tokens.contiguous().view(-1))# YOUR CODE HERE\n",
    "    \n",
    "    # train with backprop\n",
    "    # YOUR CODE HERE\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    history.append(loss.data.numpy())\n",
    "    if (i+1)%100==0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history,label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhsaTb4r2ey4"
   },
   "source": [
    "### RNN: sampling\n",
    "Once we've trained our network a bit, let's get to actually generating stuff. \n",
    "All we need is the single rnn step function you have defined in `char_rnn.forward`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true,
    "id": "CLipdW_n2ey4"
   },
   "outputs": [],
   "source": [
    "def generate_sample(char_rnn, seed_phrase=' ', max_length=MAX_LENGTH, temperature=1.0):\n",
    "    '''\n",
    "    The function generates text given a phrase of length at least SEQ_LENGTH.\n",
    "    :param seed_phrase: prefix characters. The RNN is asked to continue the phrase\n",
    "    :param max_length: maximum output length, including seed_phrase\n",
    "    :param temperature: coefficient for sampling.  higher temperature produces more chaotic outputs,\n",
    "                        smaller temperature converges to the single most likely output\n",
    "    '''\n",
    "    \n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    x_sequence = torch.tensor([x_sequence], dtype=torch.int64)\n",
    "    hid_state = char_rnn.initial_state(batch_size=1)\n",
    "    \n",
    "    #feed the seed phrase, if any\n",
    "    for i in range(len(seed_phrase) - 1):\n",
    "        hid_state, _ = char_rnn(x_sequence[:, i], hid_state)\n",
    "    \n",
    "    #start generating\n",
    "    for _ in range(max_length - len(seed_phrase)):\n",
    "        hid_state, logits = char_rnn(x_sequence[:, -1], hid_state)\n",
    "        p_next = F.softmax(logits / temperature, dim=-1).data.numpy()[0]\n",
    "        \n",
    "        # sample next token and push it back into x_sequence\n",
    "        next_ix = np.random.choice(num_tokens,p=p_next)\n",
    "        next_ix = torch.tensor([[next_ix]], dtype=torch.int64)\n",
    "        x_sequence = torch.cat([x_sequence, next_ix], dim=1)\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence.data.numpy()[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "s = [54, 232, 12]\n",
    "s = torch.tensor([s], dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([54])\n",
      "tensor([232])\n"
     ]
    }
   ],
   "source": [
    "for i in range(3 - 1):\n",
    "        print(s[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['W',\n",
       " 'e',\n",
       " 's',\n",
       " 'p',\n",
       " 'L',\n",
       " 'A',\n",
       " 'c',\n",
       " 'R',\n",
       " 'X',\n",
       " 'm',\n",
       " 'Y',\n",
       " 'B',\n",
       " 'o',\n",
       " 'F',\n",
       " 'P',\n",
       " 'S',\n",
       " 'D',\n",
       " 'n',\n",
       " 'v',\n",
       " 'M',\n",
       " 'w',\n",
       " 'V',\n",
       " 'Q',\n",
       " '-',\n",
       " 'a',\n",
       " 'k',\n",
       " 'N',\n",
       " 'u',\n",
       " 'i',\n",
       " 'G',\n",
       " 't',\n",
       " 'q',\n",
       " 'f',\n",
       " 'T',\n",
       " 'g',\n",
       " 'x',\n",
       " ' ',\n",
       " \"'\",\n",
       " 'H',\n",
       " 'h',\n",
       " 'b',\n",
       " 'I',\n",
       " 'z',\n",
       " 'j',\n",
       " 'J',\n",
       " 'E',\n",
       " 'l',\n",
       " 'r',\n",
       " 'Z',\n",
       " 'y',\n",
       " 'U',\n",
       " 'C',\n",
       " 'd',\n",
       " 'O',\n",
       " 'K']"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Ansa           '"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_sample(char_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "id": "PuCQ_Tmo2ey4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Rooha          \n",
      " Walia          \n",
      " Forla          \n",
      " Viomaden       \n",
      " VZenterl       \n",
      " Anrsy          \n",
      " Anbindle       \n",
      " Lis            \n",
      " Rjothar        \n",
      " Ewssiie        \n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sample(char_rnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "id": "BxhdezDQ2ey4",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " adasdadan      \n",
      " adasdada       \n",
      " adasdada       \n",
      " adasdada       \n",
      " adasdada       \n",
      " adasdada       \n",
      " adasdadan      \n",
      " adasdada       \n",
      " adasdada       \n",
      " adasdaday      \n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    print(generate_sample(char_rnn, seed_phrase=' adasdada'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "id": "HRuZR5RI2ey4"
   },
   "source": [
    "### More seriously\n",
    "\n",
    "What we just did is a manual low-level implementation of RNN. While it's cool, i guess you won't like the idea of re-writing it from scratch on every occasion. \n",
    "\n",
    "As you might have guessed, torch has a solution for this. To be more specific, there are two options:\n",
    "* `nn.RNNCell(emb_size, rnn_num_units)` - implements a single step of RNN just like you did. Basically concat-linear-tanh\n",
    "* `nn.RNN(emb_size, rnn_num_units` - implements the whole rnn_loop for you.\n",
    "\n",
    "There's also `nn.LSTMCell` vs `nn.LSTM`, `nn.GRUCell` vs `nn.GRU`, etc. etc.\n",
    "\n",
    "In this example we'll rewrite the char_rnn and rnn_loop using high-level rnn API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true,
    "id": "wFQPj0Yr2ey4"
   },
   "outputs": [],
   "source": [
    "class CharRNNLoop(nn.Module):\n",
    "    def __init__(self, num_tokens=num_tokens, emb_size=16, rnn_num_units=64):\n",
    "        super(self.__class__, self).__init__()\n",
    "        self.emb = nn.Embedding(num_tokens, emb_size)\n",
    "        self.rnn = nn.LSTM(emb_size, rnn_num_units, batch_first=True)\n",
    "        self.hid_to_logits = nn.Linear(rnn_num_units, num_tokens)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        assert isinstance(x.data, torch.LongTensor)\n",
    "        h_seq, _ = self.rnn(self.emb(x))\n",
    "        next_logits = self.hid_to_logits(h_seq)\n",
    "        next_logp = F.log_softmax(next_logits, dim=-1)\n",
    "        return next_logp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "ltymAjFb2ey4"
   },
   "outputs": [],
   "source": [
    "model = CharRNNLoop()\n",
    "opt = torch.optim.Adam(model.parameters())\n",
    "history = []\n",
    "\n",
    "# the model applies over the whole sequence\n",
    "batch_ix = to_matrix(sample(names, 32), max_len=MAX_LENGTH)\n",
    "batch_ix = torch.LongTensor(batch_ix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7944"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 16])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_ix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true,
    "id": "sm6r470B2ey4"
   },
   "outputs": [],
   "source": [
    "logp_seq = model(batch_ix)\n",
    "\n",
    "loss = criterion(logp_seq[:, :-1].contiguous().view(-1, num_tokens),\n",
    "                 batch_ix[:, 1:].contiguous().view(-1))\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "id": "Gu-fQkG32ey4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90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\nFcQPKOQvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = 16\n",
    "\n",
    "for i in range(1000):\n",
    "    \n",
    "    opt.zero_grad()\n",
    "    \n",
    "    batch_ix = to_matrix(sample(names, 32), max_len=MAX_LENGTH)\n",
    "    batch_ix = torch.tensor(batch_ix, dtype=torch.int64)\n",
    "    \n",
    "    logp_seq = model(batch_ix)\n",
    "    \n",
    "    # compute loss\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    # train with backprop\n",
    "\n",
    "    # YOUR CODE HERE\n",
    "    # compute loss\n",
    "    predictions_logp = logp_seq[:, :-1]# YOUR CODE HERE\n",
    "    actual_next_tokens = batch_ix[:, 1:] # YOUR CODE HERE\n",
    "\n",
    "    loss = criterion(predictions_logp.contiguous().view(-1, num_tokens), \n",
    "                  actual_next_tokens.contiguous().view(-1))# YOUR CODE HERE\n",
    "    \n",
    "    # train with backprop\n",
    "    # YOUR CODE HERE\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    \n",
    "    \n",
    "    history.append(loss.data.numpy())\n",
    "    if (i+1)%100==0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history,label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvP1qqqE2ey4"
   },
   "source": [
    "### To sum up:\n",
    "- PyTorch is convenient both for prototyping and production\n",
    "- There are a lot of pre-implemented methods/layers/activations out of the box\n",
    "- It's much easier (*really easier*) to use PyTorch than TensorFlow on entry level. \n",
    "- Neural networks are not *black boxes*, they are pretty nice and easy to use (almost always)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2C2qZ0YG2ey4"
   },
   "source": [
    "### Try it out!\n",
    "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
    "\n",
    "* Novels/poems/songs of your favorite author\n",
    "* News titles/clickbait titles\n",
    "* Source code of Linux or Tensorflow\n",
    "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
    "* Melody in notes/chords format\n",
    "* Ikea catalog titles\n",
    "* Pokemon names\n",
    "* Cards from Magic, the Gathering / Hearthstone\n",
    "\n",
    "If you're willing to give it a try, here's what you wanna look at:\n",
    "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
    "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
    "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
    "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
    "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
    "\n",
    "__Good hunting!__"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "week0_10_Names_generation_from_scratch.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
