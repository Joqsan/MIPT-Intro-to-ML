{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# 1. Introduction.\n",
    "\n",
    "- In the previous lecture we discussed mostly полносвязный слой (fully connected network).\n",
    "    - A fully connected layer is a linear model.\n",
    "- Sometimes our original data has some structure that has to be taken into account when training a model. This is also the case when we are using NN.\n",
    "    - Example: Speech:\n",
    "        - A group of word having a predefined semantic order produces a sentence, which has a meaning.\n",
    "    - Example: An image.\n",
    "        - There is a relationship between neighboring pixels.\n",
    "- That is, we have to perform trasformations, such that the structure of the data is preserved\n",
    "    - FC Layer work of with pixels independent from each other, but the meaningfulness of a picture is not contained in each pixel separately but in the way the are group together. The same thing with speech.\n",
    "    \n",
    "\n",
    "- Фраза: **<font color=green>Сегодня утром шел доджь, поэтому на работу взял с собой</font><font color=red> зонт</font>.**\n",
    "- Context: **<font color=green>Сегодня утром шел доджь, поэтому на работу взял с собой</font>**.\n",
    "    - The part of the text that we use to predict the next word.\n",
    "    - Требование 1: The context has to be encoded in a vector of finite dimensions. The dimensions are fixed: don't depend on the context's length.\n",
    "    - Требование 2: It has to be able to actualize itself by adding new information (i.e., we can (and need) add a word to the context.\n",
    "- **Question:** How to vectorize a text?\n",
    "- **Answer:** We can think of a word is a vector element from the space generated by the dictionary. A dictionary is finite, so that space is also finite. Then we can think of each word as being a one-hot vector.\n",
    "\n",
    "- RNN workflow from layer $i$ to layer $i+1$:\n",
    "    - Suppose $\\text{context}_i$ is the context right before the $i$-th layer.\n",
    "    - Concatenate to it the new $\\text{input} \\implies$ gives $\\text{context}_i^{\\text{new}} = [\\text{context}_i, \\text{input}]$.\n",
    "    - Perform a linear transformation $f(x) = Wx + b$, such that $f(\\text{context}_i^{\\text{new}})\\text{.shape} = \\text{context}_i\\text{.shape}$.\n",
    "    - Pass $\\text{context}_i^{\\text{new}}$ through a nonlinear activation function $g(\\cdot) \\implies  \\text{context}_{i+1} = g\\big(f(\\text{context}_i^{\\text{new}})\\big)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![alt text](https://i.ibb.co/NLX107n/Screen-Shot-2020-11-28-at-01-39-24.png)\n",
    "\n",
    "![alt text](https://i.ibb.co/qWBQRZ8/Screen-Shot-2020-11-28-at-01-53-41.png)\n",
    "\n",
    "- $h_i$ - **_context_** vector or **_hidden state_**.\n",
    "- $x_i$ - input vector (the new information).\n",
    "\n",
    "\n",
    "![alt text](https://i.ibb.co/pbdRSRP/Screen-Shot-2020-11-28-at-01-59-03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - It seems that if at some point the network wrongly predicted a word, then downwards the predictions will also be wrong, since it'll be using that word from predicting across the subsequent layers.\n",
    " - `<START>` and `<END>` denote the limits of the sentence (they're called **_tokens_**).\n",
    "     - This controls the points where the model start and end predictions.\n",
    "     - This also allows to take $h_0 = \\vec{0}$.\n",
    "     \n",
    "----\n",
    "\n",
    "# 2. RNN Drawbacks.\n",
    "\n",
    "- $h_i$ changes at each step: each input brings some sort of perturbation to the hidden state $\\implies h_i$ has no change of passing through layers without changes.\n",
    "    - Example of this being a problem: Speech with a lot of hesitations markers (_hmmm, eeh, este, o sea_). The marker doesn't add any meaningful new information to the context (in fact, they may be eliminated), by when dealing with an unprocessed transcription they will introduce change in the hidden state anyway.\n",
    "        - Since each _hmmm, eeh, este, o sea_ will be a token feed to the network as input.\n",
    "    - In general, the hidden state will change even is the input data contains some small noise.\n",
    "\n",
    "- $\\implies$ we'd want the model to decide what input are inportant than others. This is where LSTM comes to the rescue.\n",
    "\n",
    "# 3. LSTM.\n",
    "\n",
    "![alt text](https://i.ibb.co/znv3nVX/Screen-Shot-2020-11-28-at-17-03-02.png)\n",
    "\n",
    "<h1><center>$\\Downarrow$</center></h1>\n",
    "\n",
    "![alt text](https://i.ibb.co/zFPr3DK/Screen-Shot-2020-11-28-at-17-03-12.png)\n",
    "\n",
    "- Here we use $\\tanh$ instead of ReLU or LeakyReLU because the latter functions are not bounded, and the hidden steps can turn out to be anything when forward passing. This we want to avoid, since we'd want to pass to each layer data having the same distribution.\n",
    "    - $\\tanh$ and $\\sigma$ are bounded functions.\n",
    "    - врата - gate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3.1. LSTM Overview.\n",
    "\n",
    "### 3.1.0. Notation.\n",
    "\n",
    "- The notaiton changes a little bit.\n",
    "\n",
    "![alt text](https://i.ibb.co/hgZ2SJn/Screen-Shot-2020-11-28-at-17-24-50.png)\n",
    "\n",
    "- $h^{(t-1)}$ - hidden state coming from the previous layer.\n",
    "- $x^{(t)}$ - input the the $t$-th layer.\n",
    "- $h^{(t)}$ - updated hidden state with the $x^{(t)}$ input.\n",
    "\n",
    "![alt text](https://i.ibb.co/s3qCKTV/Screen-Shot-2020-11-28-at-17-46-03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Another drawback.\n",
    "\n",
    "- Before we talk about the importanec of having bounded activation function. The problem is that for large positive/small negative values $\\tanh$ and $\\sigma$ leads to vanshing gradient.\n",
    "- Specifically, during backpropagation, the further we go back to the beginning on the network updating gradient, the more the gradient diminishes $\\implies$ during optimization, the loss function will practically ignore the contribution of the earlier layers.\n",
    "\n",
    "![alt text](https://i.ibb.co/dmhG42V/Screen-Shot-2020-11-28-at-18-45-15.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
