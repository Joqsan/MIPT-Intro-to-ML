{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 1. Warm-Up Test.\n",
    "\n",
    "- Оступ: Margin.\n",
    "- For regularization normalize features.\n",
    "- Regularizing linear model (with L1 or L2 regularization) is useful, because it's clear what we regularize upon. With models like kNN and Naives Bayes is not clear what the parameters are (what we can denote as $w$).\n",
    "- Cross-validation by default can be used only when our data is unordered.\n",
    "    - If the data has some internal structure, we must take it into account when cross-validating.\n",
    "        - For example, with time series we should train in the past and validate in the future.\n",
    "        \n",
    "----\n",
    "\n",
    "\n",
    "# 2. Probability Calibration.\n",
    "\n",
    "- It relates the probability of an object belonging to the positive class to the proportion of object belonging to the **in a fixed bin**.\n",
    "- Precisely mean predicted class vs. true fraction of class 1.\n",
    "    - predicted probability = how confidence we are that the object belong to class 1 = what portion of objects we expect to be from class 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
